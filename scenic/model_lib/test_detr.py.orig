"""Tests for detr.py."""

import os

from absl.testing import absltest
from absl.testing import parameterized
from flax import jax_utils
from flax import nn
import jax
from jax import random
import jax.numpy as jnp
import ml_collections
import numpy as onp
from scenic.dataset_lib import coco_eval
from scenic.model_lib import detr

NUM_COCO_CLASSES = 81  # COCO (non-panoptic) uses 80 classes, + background.


class DETRTest(parameterized.TestCase):
  """Tests for detr.py."""

  def test_input_pos_embedding_learned(self):
    """Tests InputPosEmbeddingLearned."""
    rng = random.PRNGKey(0)
    inputs_shape = (8, 32, 19, 64)

    positional_embedding_def = detr.InputPosEmbeddingLearned.partial(
        inputs_shape=inputs_shape, hidden_dim=64, max_h_w=50)
    pos, _ = positional_embedding_def.init(rng)
    # test output shape
    self.assertEqual(pos.shape, (1, 32 * 19, 64))

  def test_input_pos_embedding_sine(self):
    """Tests InputPosEmbeddingSine."""
    rng = random.PRNGKey(0)
    b, h, w, hidden = (8, 32, 19, 64)
    padding_mask = onp.zeros((b, h, w))
    padding_mask[:, 16:, :] = 0
    padding_mask[:, :, 16:] = 0

    positional_embedding_def = detr.InputPosEmbeddingSine.partial(
        padding_mask=padding_mask, hidden_dim=hidden)
    pos, _ = positional_embedding_def.init(rng)
    # test output shape
    self.assertEqual(pos.shape, (b, h * w, hidden))

  def test_query_pos_embedding(self):
    """Tests QueryPosEmbedding."""
    rng = random.PRNGKey(0)
    positional_embedding_def = detr.QueryPosEmbedding.partial(
        hidden_dim=64, num_queries=100)
    query_pos, _ = positional_embedding_def.init(rng)
    # test output shape
    self.assertEqual(query_pos.shape, (1, 100, 64))

  @parameterized.named_parameters(
      ('test_without_intermediate', False, (8, 100, 64)),
      ('test_wit_intermediate', True, (6, 8, 100, 64)),
  )
  def test_detr_transformer_output_shape(self, return_intermediate,
                                         expected_output_shape):
    """Test DETRTransformer output shape."""
    rng = random.PRNGKey(0)
    inputs_shape = (8, 20 * 20, 64)
    num_query_objects = 100
    num_decoder_layers = 6
    inputs = jnp.array(onp.random.normal(size=inputs_shape))
    query_pos_emb = jnp.array(
        onp.random.normal(size=(1, num_query_objects, 64)))

    # test output shape of DETR Transformer model
    detr_transformer_def = detr.DETRTransformer.partial(
        num_queries=num_query_objects,
        qkv_dim=64,
        num_heads=4,
        query_pos_emb=query_pos_emb,
        num_decoder_layers=num_decoder_layers,
        return_intermediate_dec=return_intermediate)

    dropout_rng, init_rng = random.split(rng)
    with nn.stochastic(dropout_rng):
      outputs, _ = detr_transformer_def.init(init_rng, inputs)
    self.assertEqual(outputs.shape, expected_output_shape)


class DETRSetDetectionModelTest(parameterized.TestCase):
  """Test DETRSetDetectionModel."""

  def setUp(self):
    super(DETRSetDetectionModelTest, self).setUp()

    self.num_classes = 5
    self.input_shape = (3, 128, 128, 3)

    # create and initialize the model
    model_cls = detr.DETRSetDetectionModel
    self.model = model_cls(
        hparams=None,
        dataset_meta_data={
            'num_classes': self.num_classes,
            'target_is_onehot': False,
        })
    hparams_loss = ml_collections.ConfigDict(
        dict(
            num_aux_outputs=2,
            bbox_loss_coef=1.0,
            giou_loss_coef=1.0,
            eos_coef=1.0))
    self.model.hparams.update(hparams_loss)
    rng = random.PRNGKey(0)
    rng, params_rng, dropout_rng = random.split(rng, 3)
    with nn.stateful() as init_model_state:
      with nn.stochastic(dropout_rng):
        flax_module_def = self.model.flax_module_def.partial(train=False)
        _, initial_params = flax_module_def.init_by_shape(
            params_rng, [(self.input_shape, jnp.float32)])
    flax_module = nn.Model(flax_module_def, initial_params)

    # a fake batch with 3 examples
    self.batch = {
        'inputs':
            jnp.array(onp.random.normal(size=self.input_shape)
                     ).astype(jnp.float32),
        'padding_mask':
            jnp.array(onp.random.normal(size=self.input_shape[:-1])
                     ).astype(jnp.float32),
        'label': {
            'labels':
                jnp.array(
                    onp.random.randint(
                        self.num_classes,
                        size=(3, self.model.hparams.num_queries))),
            'boxes':
                jnp.array(
                    onp.random.uniform(
                        size=(3, self.model.hparams.num_queries, 4),
                        low=0.0,
                        high=1.0),
                    dtype=jnp.float32),
        }
    }

    rng, dropout_rng = random.split(rng)
    with nn.stateful(init_model_state):
      with nn.stochastic(dropout_rng):
        self.outputs = flax_module(
            self.batch['inputs'], padding_mask=self.batch['padding_mask'])

    seq = onp.arange(self.model.hparams.num_queries, dtype=onp.int32)
    seq_rev = seq[::-1]
    seq_21 = onp.concatenate([
        seq[self.model.hparams.num_queries // 2:],
        seq[:self.model.hparams.num_queries // 2]
    ])
    self.indices = jnp.array([(seq, seq_rev), (seq_rev, seq), (seq, seq_21)])

  def is_valid(self, t):
    """Helper function to assert that tensor `t` does not have `nan`, `inf`."""
    self.assertFalse(jnp.isnan(t).any(), msg=f'Found nan\'s in {t}')
    self.assertFalse(jnp.isinf(t).any(), msg=f'Found inf\'s in {t}')

  def is_valid_loss(self, loss):
    """Helper function to assert that `loss` is of shape [] and `is_valid`."""
    self.assertSequenceEqual(loss.shape, [])
    self.is_valid(loss)

  @parameterized.named_parameters(
      ('without_log', False, ['loss_ce']),
      ('with_log', True, ['loss_ce', 'class_accuracy']))
  def test_labels_losses_and_metrics(self, log, metrics_key):
    """Test loss_labels by checking its output's dictionary format.

    Args:
      log: bool; Whether do logging or not in labels_losses_and_metrics.
      metrics_key: list; Expected metric keys.
    """
    # test loss function in the pmapped setup
    labels_lm_pmapped = jax.pmap(
        self.model.labels_losses_and_metrics,
        static_broadcasted_argnums=(2, 3),
        axis_name='batch')

    outputs, batch = (jax_utils.replicate(self.outputs),
                      jax_utils.replicate(self.batch))

    losses, metrics = labels_lm_pmapped(outputs, batch, self.indices, log)
    losses = jax_utils.unreplicate(losses)
    metrics = jax_utils.unreplicate(metrics)
    self.assertSameElements(losses.keys(), ['loss_ce'])
    self.is_valid_loss(losses['loss_ce'])
    self.assertSameElements(metrics.keys(), metrics_key)
    for mk in metrics_key:
      self.is_valid(metrics[mk][0])
      self.is_valid(metrics[mk][1])

  def test_boxes_losses_and_metrics(self):
    """Test loss_boxes by checking its output's dictionary format."""

    # test loss function in the pmapped setup
    boxes_lm_pmapped = jax.pmap(
        self.model.boxes_losses_and_metrics,
        static_broadcasted_argnums=(2,),
        axis_name='batch')

    outputs_replicate, batch_replicate = (jax_utils.replicate(self.outputs),
                                          jax_utils.replicate(self.batch))

    losses, metrics = boxes_lm_pmapped(outputs_replicate, batch_replicate,
                                       self.indices)
    losses = jax_utils.unreplicate(losses)
    metrics = jax_utils.unreplicate(metrics)

    self.assertSameElements(losses.keys(), ['loss_bbox', 'loss_giou'])
    self.is_valid_loss(losses['loss_bbox'])
    self.is_valid_loss(losses['loss_giou'])

    self.assertSameElements(metrics.keys(), ['loss_bbox', 'loss_giou'])
    for i in range(2):  # metric and its normalizer
      self.is_valid(metrics['loss_bbox'][i])
      self.is_valid(metrics['loss_giou'][i])


class DETRSetDetectionModelTestWithAuxLoss(parameterized.TestCase):
  """Test DETRSetDetectionModel with auxilary loss."""

  def setUp(self):
    super(DETRSetDetectionModelTestWithAuxLoss, self).setUp()

    self.num_classes = 5
    self.input_shape = (3, 128, 128, 3)
    hparams = ml_collections.ConfigDict(
        dict(
            hidden_dim=32,
            num_queries=8,
            query_emb_size=None,
            transformer_num_heads=2,
            transformer_num_encoder_layers=1,
            transformer_qkv_dim=32,
            transformer_mlp_dim=32,
            transformer_max_input_h_w=50,
            transformer_normalize_before=False,
            backbone_num_filters=32,
            backbone_num_layers=1,
            dropout_rate=0.1,
            bbox_loss_coef=1.0,
            giou_loss_coef=1.0,
            eos_coef=1.0,
            # for this test:
            aux_loss=True,
            transformer_num_decoder_layers=3,
            num_aux_outputs=2,
            matcher=None,
        ))

    # create and initialize the model
    model_cls = detr.DETRSetDetectionModel
    self.model = model_cls(
        hparams=hparams,
        dataset_meta_data={
            'num_classes': self.num_classes,
            'target_is_onehot': False,
        })

    rng = random.PRNGKey(0)
    rng, params_rng, dropout_rng = random.split(rng, 3)
    with nn.stateful() as init_model_state:
      with nn.stochastic(dropout_rng):
        flax_module_def = self.model.flax_module_def.partial(train=False)
        _, initial_params = flax_module_def.init_by_shape(
            params_rng, [(self.input_shape, jnp.float32)])
    flax_module = nn.Model(flax_module_def, initial_params)

    # a fake batch with 3 examples
    self.batch = {
        'inputs':
            jnp.array(onp.random.normal(size=self.input_shape)
                     ).astype(jnp.float32),
        'padding_mask':
            jnp.array(onp.random.normal(size=self.input_shape[:-1])
                     ).astype(jnp.float32),
        'label': {
            'labels':
                jnp.array(
                    onp.random.randint(
                        self.num_classes,
                        size=(3, self.model.hparams.num_queries))),
            'boxes':
                jnp.array(
                    onp.random.uniform(
                        size=(3, self.model.hparams.num_queries, 4),
                        low=0.0,
                        high=1.0),
                    dtype=jnp.float32),
        }
    }
    rng, dropout_rng = random.split(rng)
    with nn.stateful(init_model_state):
      with nn.stochastic(dropout_rng):
        self.outputs = flax_module(
            self.batch['inputs'], padding_mask=self.batch['padding_mask'])

  def test_loss_function(self):
    """Test loss_function by checking its output's dictionary format."""

    # test loss function in the pmapped setup
    loss_function_pmapped = jax.pmap(
        self.model.loss_function, axis_name='batch')

    outputs_replicated, batch_replicated = (jax_utils.replicate(self.outputs),
                                            jax_utils.replicate(self.batch))

    total_loss, metrics_dict = loss_function_pmapped(outputs_replicated,
                                                     batch_replicated)

    total_loss, metrics_dict = (jax_utils.unreplicate(total_loss),
                                jax_utils.unreplicate(metrics_dict))

    # collect what keys we expect to find in the metrics_dict
    base = [
        'class_accuracy',
        'loss_ce',
        'cardinality_error',
        'loss_bbox',
        'loss_giou',
        'minibatch_object_detection_loss',
        'loss_ce_0',
        'cardinality_error_0',
        'loss_bbox_0',
        'loss_giou_0',
        'loss_ce_1',
        'cardinality_error_1',
        'loss_bbox_1',
        'loss_giou_1',
    ]
    base_unscaled = []
    for b in base:
      if b in self.model.loss_terms_weights.keys():
        base_unscaled.append(b + '_unscaled')
      else:
        base_unscaled.append(b)
    base_scaled = [
        'loss_ce',
        'loss_bbox',
        'loss_giou',
        'loss_ce_0',
        'loss_bbox_0',
        'loss_giou_0',
        'loss_ce_1',
        'loss_bbox_1',
        'loss_giou_1',
    ]
    expected_metrics_keys = base_unscaled + base_scaled
    self.assertSameElements(expected_metrics_keys, metrics_dict.keys())

    # because weight decay is not used, the following must hold
    object_detection_loss = 0
    for k in metrics_dict.keys():
      # if this loss going to be included in the total object dtection loss
      if k in self.model.loss_terms_weights.keys():
        # get the normalizer for this loss
        object_detection_loss += (
            # already scaled loss term / loss term normalizer
            metrics_dict[k][0] / metrics_dict[k][1])
    self.assertAlmostEqual(total_loss, object_detection_loss, places=3)

  def test_coco_global_val_metrics_function_results(self):
    """Test set_detection_global_metrics_function correctness on a single box."""
    test_annotations_path = os.path.join(
        os.path.normpath(os.path.dirname(__file__) + '/../'), 'dataset_lib',
        'data', 'instances_val2017_unittest.json')

    coco_evaluator = coco_eval.CocoEvaluator(
        annotations_loc=test_annotations_path, threshold=0.0)

    # Manually create a single example that has known results.
    # A single box, values taken from ground-truth annotations and manually
    # converted to relative [cx, cy, w, h] format:
    h, w = 427, 640
    bx, by, bw, bh = 217.62, 240.54, 38.99, 57.75

    outputs = {}
    outputs['pred_boxes'] = onp.array([
        [(bx + bw / 2) / w, (by + bh / 2) / h, bw / w, bh / h],
    ])
    outputs['pred_boxes'] = jnp.asarray(outputs['pred_boxes'])
    outputs['pred_logits'] = onp.zeros((1, NUM_COCO_CLASSES))
    outputs['pred_logits'][0, 1] = 100.0

    targets = {}
    targets['orig_size'] = onp.array([h, w])
    targets['image/id'] = onp.array([397133])

    metrics = detr.coco_global_val_metrics_function(
        all_predictions=[outputs],
        all_targets=[targets],
        coco_evaluator=coco_evaluator)

    self.assertAlmostEqual(metrics['AP'], 1.0, 5)
    self.assertAlmostEqual(metrics['AP_50'], 1.0, 5)
    self.assertAlmostEqual(metrics['AP_75'], 1.0, 5)
    self.assertAlmostEqual(metrics['AP_small'], -1.0, 5)
    self.assertAlmostEqual(metrics['AP_medium'], 1.0, 5)
    self.assertAlmostEqual(metrics['AP_large'], -1.0, 5)
    self.assertAlmostEqual(metrics['AR_max_1'], 1.0, 5)
    self.assertAlmostEqual(metrics['AR_max_10'], 1.0, 5)
    self.assertAlmostEqual(metrics['AR_max_100'], 1.0, 5)
    self.assertAlmostEqual(metrics['AR_small'], -1.0, 5)
    self.assertAlmostEqual(metrics['AR_medium'], 1.0, 5)
    self.assertAlmostEqual(metrics['AR_large'], -1.0, 5)


if __name__ == '__main__':
  absltest.main()
