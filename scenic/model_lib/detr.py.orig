"""Implementation of DETR architecture.

End-to-End Object Detection with Transformers: https://arxiv.org/abs/2005.12872
Implementation is based on: https://github.com/facebookresearch/detr
"""

import functools

from flax import nn
import jax
from jax import lax
from jax.nn import initializers
import jax.numpy as jnp
import ml_collections
import numpy as onp
from scenic.dataset_lib import coco_eval
from scenic.model_lib import resnet
from scenic.model_lib.base_models import model_utils
from scenic.model_lib.base_models.set_detection_model import SetDetectionModel
from scenic.model_lib.layers import attention_layers

# TODO(scenic): check the initializations
# TODO(scenic): add support for DC5 in the backbone


def coco_global_val_metrics_function(all_predictions, all_targets,
                                     coco_evaluator):
  """Computes metrics that require the prediction for the entire dataset.

  Args:
    all_predictions: list; predictions of the model for all examples in the set,
      where each element in the list is a dictionary of 'pred_img_ids',
      'pred_logits' in shape of `[num_objects, num_classes]` and 'pred_boxes' in
      shape of `[num_objects, 4]`. Box coordinates should be in raw DETR format,
      i.e. [cx, cy, w, h] in range [0, 1].
    all_targets: list of targets corresponding to elements in all_predictions,
      where each element is a dict of 'orig_size', 'size', and 'image/id'.
    coco_evaluator: coco_eval.CocoEvaluator object to perform the evaluation.

  Returns:
    A dictionary that has metrics with their name as keys.
  """

  # Run evaluation on the model
  coco_evaluator.clear_annotations()  # Clear former annotations
  for pred, target in zip(all_predictions, all_targets):
    # Convert from DETR [cx, cy, w, h] to COCO [x, y, w, h] bounding box format:
    boxes = model_utils.box_cxcywh_to_xyxy(pred['pred_boxes'])
    boxes = onp.array(boxes)
    boxes[:, 2] -= boxes[:, 0]
    boxes[:, 3] -= boxes[:, 1]

    # Scale from relative to absolute size:
    # Note that the padding is implemented such that such that the model's
    # predictions are [0,1] normalized to the non-padded image, so scaling by
    # `orig_size` will convert correctly to the original image coordinates. No
    # image flipping happens during evaluation.
    h, w = onp.asarray(target['orig_size'])
    scale_factor = onp.array([w, h, w, h])
    boxes = boxes * scale_factor[onp.newaxis, :]

    # Get scores, excluding the background class:
    scores = jax.nn.softmax(pred['pred_logits'], axis=-1)[:, 1:]

    # Add example to evaluator:
    coco_evaluator.add_annotation(
        bboxes=onp.asarray(boxes),
        scores=onp.asarray(scores),
        img_id=int(target['image/id']))

  return coco_evaluator.compute_coco_metrics()


class QueryPosEmbedding(nn.Module):
  """Creates learned positional embeddings for object queries."""

  def apply(self,
            hidden_dim,
            num_queries,
            posemb_init=initializers.normal(stddev=1.0),
            dtype=jnp.float32):
    """Creates the positional embeddings for queries.

    Args:
      hidden_dim: int; Hidden dimension for the pos embeddings.
      num_queries: int; Number of object queries.
      posemb_init: int; Positional embeddings initializer.
      dtype: Jax dtype; The dtype of the computation (default: float32).

    Returns:
      Positional embedding for object queries.
    """
    query_pos = self.param('query_emb', (num_queries, hidden_dim), posemb_init)
    query_pos = jnp.expand_dims(query_pos, 0)
    return jnp.asarray(query_pos, dtype)


class InputPosEmbeddingLearned(nn.Module):
  """Creates learned positional embeddings for inputs."""

  def apply(self,
            inputs_shape,
            hidden_dim,
            max_h_w=50,
            posemb_init=initializers.uniform(scale=1.0),
            dtype=jnp.float32):
    """Creates the positional embeddings for transformer inputs.

    Args:
      inputs_shape: tuple; Shape of the 2D input, before flattening.
      hidden_dim: int; hidden dimension for the pos embeddings.
      max_h_w: int; Maximum height and width for the transformer inputs.
      posemb_init: int; Positional embeddings initializer.
      dtype: Jax dtype; The dtype of the computation (default: float32).

    Returns:
      Positional embedding for inputs and queries.
    """
    _, h, w, _ = inputs_shape
    assert h <= max_h_w and w <= max_h_w

    row_pos_embed = self.param('row_pos_embed', (max_h_w, hidden_dim // 2),
                               posemb_init)
    col_pos_embed = self.param('col_pos_embed', (max_h_w, hidden_dim // 2),
                               posemb_init)

    # to `[h, w, hidden_dim//2]`
    x_pos_emb = jnp.tile(jnp.expand_dims(col_pos_embed[:w], axis=0), (h, 1, 1))
    # to `[h, w, hidden_dim//2]`
    y_pos_emb = jnp.tile(jnp.expand_dims(row_pos_embed[:h], axis=1), (1, w, 1))
    # to `[1, h*w, hidden_dim]`
    pos = jnp.expand_dims(
        jnp.concatenate((x_pos_emb, y_pos_emb), axis=-1).reshape(
            (h * w, hidden_dim)),
        axis=0)

    return jnp.asarray(pos, dtype)


class InputPosEmbeddingSine(nn.Module):
  """Creates sinusoidal positional embeddings for inputs."""

  def apply(self,
            padding_mask,
            hidden_dim,
            dtype=jnp.float32,
            scale=None,
            temperature=10000):
    """Creates the positional embeddings for transformer inputs.

    Args:
      padding_mask: nd-array; Binary matrix with 1 at padded image regions.
      hidden_dim: int; hidden dimension for the pos embeddings.
      dtype: Jax dtype; The dtype of the computation (default: float32).
      scale: float; determines the length scale of the embeddings.
      temperature: float; determines the magnitude of the embedding values.

    Returns:
      Positional embedding for inputs.

    Raises:
      ValueError if `hidden_dim` is not an even number.
    """
    if hidden_dim % 2:
      raise ValueError(f'`hidden_dim` must be an even number, got {hidden_dim}')

    not_mask = 1.0 - padding_mask.astype(jnp.float32)
    y_embed = jnp.cumsum(not_mask, axis=1)
    x_embed = jnp.cumsum(not_mask, axis=2)

    # Normalization:
    eps = 1e-6
    scale = scale if scale is not None else 2 * jnp.pi
    y_embed = y_embed / (y_embed[:, -1:, :] + eps) * scale
    x_embed = x_embed / (x_embed[:, :, -1:] + eps) * scale

    num_pos_feats = hidden_dim // 2
    dim_t = jnp.arange(num_pos_feats, dtype=jnp.float32)
    dim_t = temperature ** (2 * (dim_t // 2) / num_pos_feats)

    pos_x = x_embed[:, :, :, jnp.newaxis] / dim_t
    pos_y = y_embed[:, :, :, jnp.newaxis] / dim_t
    pos_x = jnp.stack([
        jnp.sin(pos_x[:, :, :, 0::2]),
        jnp.cos(pos_x[:, :, :, 1::2]),
    ], axis=4).reshape(padding_mask.shape + (-1,))
    pos_y = jnp.stack([
        jnp.sin(pos_y[:, :, :, 0::2]),
        jnp.cos(pos_y[:, :, :, 1::2]),
    ], axis=4).reshape(padding_mask.shape + (-1,))

    pos = jnp.concatenate([pos_y, pos_x], axis=3)
    b, h, w = padding_mask.shape
    pos = jnp.reshape(pos, [b, h * w, hidden_dim])
    return jnp.asarray(pos, dtype)


class MultiHeadDotProductAttention(nn.Module):
  """DETR Customized Multi-head dot-product attention."""

  def apply(self,
            inputs_q,
            inputs_kv,
            num_heads,
            pos_emb_q=None,
            pos_emb_k=None,
            pos_emb_v=None,
            qkv_features=None,
            out_features=None,
            padding_mask=None,
            key_padding_mask=None,
            dropout_rate=0.,
            broadcast_dropout=False,
            kernel_init=initializers.xavier_uniform(),
            bias_init=initializers.zeros,
            bias=True,
            deterministic=False,
            dtype=jnp.float32):
    """Applies multi-head dot product attention on the input data.

    Projects the inputs into multi-headed query, key, and value vectors,
    applies dot-product attention and project the results to an output vector.

    This can be used for encoder-decoder attention by specifying both `inputs_q`
    and `inputs_kv` or for self-attention by only specifying `inputs_q` and
    setting `inputs_kv` to None.

    Args:
      inputs_q: nd-array; Input queries of shape  `[bs, len, features]`.
      inputs_kv: nd-array; Key/values of shape `[bs, len, features]` or None for
        self-attention, inn which case key/values will be derived from inputs_q.
      num_heads: int; Number of attention heads. Features (i.e.
        inputs_q.shape[-1]) should be divisible by the number of heads.
      pos_emb_q: nd-array: Positional embedding to be added to the query.
      pos_emb_k: nd-array: Positional embedding to be added to the key.
      pos_emb_v: nd-array: Positional embedding to be added to the value.
      qkv_features: dimension of the key, query, and value.
      out_features: dimension of the last projection
      padding_mask: boolean specifying query tokens that are pad token.
      key_padding_mask: boolean specifying key-value tokens that are pad token.
      dropout_rate: dropout rate
      broadcast_dropout: bool: use a broadcasted dropout along batch dims.
      kernel_init: initializer for the kernel of the Dense layers.
      bias_init: initializer for the bias of the Dense layers.
      bias: bool: whether pointwise QKV dense transforms use bias. In DETR they
        always have a bias on the output.
      deterministic: bool, deterministic or not (to apply dropout)
      dtype: the dtype of the computation (default: float32)

    Returns:
      output of shape `[bs, l, features]`.
    """

    if inputs_kv is None:
      inputs_kv = inputs_q

    assert inputs_kv.ndim == inputs_q.ndim == 3
    features = out_features or inputs_q.shape[-1]
    qkv_features = qkv_features or inputs_q.shape[-1]

    assert qkv_features % num_heads == 0, (
        'Memory dimension must be divisible by number of heads.')
    head_dim = qkv_features // num_heads

    dense = nn.DenseGeneral.partial(
        axis=-1,
        features=(num_heads, head_dim),
        kernel_init=kernel_init,
        bias_init=bias_init,
        bias=bias)
    # project inputs_q to multi-headed q/k/v
    # dimensions are then [bs, l, n_heads, n_features_per_head]
    query, key, value = (dense(inputs_q, dtype=dtype, name='query'),
                         dense(inputs_kv, dtype=dtype, name='key'),
                         dense(inputs_kv, dtype=dtype, name='value'))

    def add_positional_emb(x, pos_emb_x):
      if pos_emb_x is not None:
        # reshape to multi-head features
        return x + pos_emb_x.reshape(pos_emb_x.shape[:1] + x.shape[1:])
      else:
        return x

    query, key, value = (add_positional_emb(query, pos_emb_q),
                         add_positional_emb(key, pos_emb_k),
                         add_positional_emb(value, pos_emb_v))

    # create attention masks
    mask_components = []
    if padding_mask is not None:
      if key_padding_mask is None:
        key_padding_mask = padding_mask
      padding_mask = nn.attention.make_padding_mask(
          padding_mask_query=padding_mask,
          padding_mask_key=key_padding_mask,
          query_shape=query.shape,
          key_shape=key.shape,
          attention_axis=(1,))
      mask_components.append(padding_mask)

    if mask_components:
      attention_mask = mask_components[0]
      for component in mask_components[1:]:
        attention_mask = jnp.logical_and(attention_mask, component)

      # attention mask in the form of attention bias
      attention_bias = lax.select(
          attention_mask > 0,
          jnp.full(attention_mask.shape, 0.).astype(dtype),
          jnp.full(attention_mask.shape, -1e10).astype(dtype))
    else:
      attention_bias = None

    # apply attention
    x = nn.attention.dot_product_attention(
        query,
        key,
        value,
        dtype=dtype,
        axis=(1,),
        bias=attention_bias,
        dropout_rate=dropout_rate,
        broadcast_dropout=broadcast_dropout,
        deterministic=deterministic)

    # back to the original inputs dimensions
    out = nn.DenseGeneral(
        x,
        features=features,
        axis=(-2, -1),
        kernel_init=kernel_init,
        bias_init=bias_init,
        bias=True,
        dtype=dtype,
        name='out')

    return out


class DETRBackbone(nn.Module):
  """ResNet backbone for DETR architecture."""

  def apply(self,
            x,
            num_filters=64,
            num_layers=50,
            dtype=jnp.float32,
            update_batch_stats=True):
    """Applies ResNet backbone to the inputs.

    Args:
      x: Inputs to the module.
      num_filters: int; Num filters in ResNet.
      num_layers: int; Num layers in ResNet.
      dtype: Data type, e.g. jnp.float32.
      update_batch_stats: bool; Whether update the batch statistics in
        BatchNorms.

    Returns:
       Learned features for the inputs, in shape of `[batch_size, height,
       width, features]`.
    """
    if num_layers not in resnet.BLOCK_SIZE_OPTIONS:
      raise ValueError('Please provide a valid number of layers')
    block_sizes = resnet.BLOCK_SIZE_OPTIONS[num_layers]
    x = nn.Conv(
        x,
        num_filters, (7, 7), (2, 2),
        padding=[(3, 3), (3, 3)],
        bias=False,
        dtype=dtype,
        name='stem_conv')
    x = nn.BatchNorm(
        x,
        use_running_average=not update_batch_stats,
        momentum=0.9,
        epsilon=1e-5,
        dtype=dtype,
        name='init_bn')
    x = nn.max_pool(x, (3, 3), strides=(2, 2), padding='SAME')

    for i, block_size in enumerate(block_sizes):
      for j in range(block_size):
        strides = (2, 2) if i > 0 and j == 0 else (1, 1)
        # `resnet.ResidualBlock` is the bottleneck block for ResNet V2
        x = resnet.ResidualBlock(
            x,
            num_filters * 2**i,
            strides=strides,
            train=update_batch_stats,
            dtype=dtype)
    return x


class EncoderBlock(nn.Module):
  """DETR Transformer encoder block."""

  def apply(self,
            inputs,
            num_heads,
            qkv_dim,
            mlp_dim,
            pos_embedding=None,
            pre_norm=False,
            padding_mask=None,
            dropout_rate=0.1,
            attention_dropout_rate=0.1,
            deterministic=False,
            dtype=jnp.float32):
    """Applies EncoderBlock module.

    Args:
      inputs: nd-array; Input data of shape [batch_size, len, features].
      num_heads: int; Number of heads.
      qkv_dim: int; Dimension of the query/key/value.
      mlp_dim: int; Dimension of the mlp on top of attention block.
      pos_embedding: nd-array; Positional Embedding to be added to the inputs.
      pre_norm: bool; If use LayerNorm before attention/mlp blocks.
      padding_mask: bool; Mask padding tokens.
      dropout_rate: float; Dropout rate.
      attention_dropout_rate: float; Dropout rate for attention weights.
      deterministic: bool; Deterministic or not (to apply dropout).
      dtype: Data type of the computation (default: float32).

    Returns:
      Output after transformer encoder block.
    """
    self_attn = MultiHeadDotProductAttention.partial(
        inputs_kv=None,  # it is a self-attention
        num_heads=num_heads,
        pos_emb_q=pos_embedding,
        pos_emb_k=pos_embedding,
        pos_emb_v=None,
        qkv_features=qkv_dim,
        padding_mask=padding_mask,
        dropout_rate=attention_dropout_rate,
        broadcast_dropout=False,
        kernel_init=initializers.xavier_uniform(),
        bias_init=initializers.zeros,
        bias=True,
        deterministic=deterministic,
        dtype=dtype)

    mlp = attention_layers.MlpBlock.partial(
        mlp_dim=mlp_dim,
        activation_fn=nn.gelu,
        dtype=dtype,
        dropout_rate=dropout_rate,
        deterministic=deterministic)

    assert inputs.ndim == 3

    if pre_norm:
      # attention block
      x = nn.LayerNorm(inputs, dtype=dtype)
      x = self_attn(inputs_q=x)
      x = nn.dropout(x, rate=dropout_rate, deterministic=deterministic)
      x = x + inputs
      # mlp block
      y = nn.LayerNorm(x, dtype=dtype)
      y = mlp(y)
      out = x + y

    else:
      # attention block
      x = self_attn(inputs_q=inputs)
      x = nn.dropout(x, rate=dropout_rate, deterministic=deterministic)
      x = x + inputs
      x = nn.LayerNorm(x, dtype=dtype)
      # mlp block
      y = mlp(x)
      y = x + y
      out = nn.LayerNorm(y, dtype=dtype)

    return out


class DecoderBlock(nn.Module):
  """DETR Transformer decoder block."""

  def apply(self,
            obj_queries,
            encoder_output,
            num_heads,
            qkv_dim,
            mlp_dim,
            pos_embedding=None,
            query_pos_emb=None,
            pre_norm=False,
            key_padding_mask=None,
            dropout_rate=0.1,
            attention_dropout_rate=0.1,
            deterministic=False,
            dtype=jnp.float32):
    """Applies DecoderBlock module.

    Args:
      obj_queries: nd-array; Input data for decoder.
      encoder_output: nd-array; Output of encoder, which are encoded inputs.
      num_heads: int; Number of heads.
      qkv_dim: int; Dimension of the query/key/value.
      mlp_dim: int; Dimension of the mlp on top of attention block.
      pos_embedding: nd-array; Positional Embedding to be added to the inputs.
      query_pos_emb: nd-array; Positional Embedding to be added to the queries.
      pre_norm: bool; If use LayerNorm before attention/mlp blocks.
      key_padding_mask: bool; Mask padding tokens for keys.
      dropout_rate: float; Dropout rate.
      attention_dropout_rate: float; Dropout rate for attention weights.
      deterministic: bool; Deterministic or not (to apply dropout).
      dtype: Data type of the computation (default: float32).

    Returns:
      Output after transformer decoder block.
    """

    assert query_pos_emb is not None, ('Given that object_queries are zeros '
                                       'and  not learnable, we should add '
                                       'learnable query_pos_emb to them.')
    # seems in DETER the self-attention in the first layer basically does
    # nothing, as the  value vector is a zero vector and we add no learnable
    # positional embedding to it!
    self_attn = MultiHeadDotProductAttention.partial(
        inputs_kv=None,  # self-attention,
        num_heads=num_heads,
        pos_emb_q=query_pos_emb,
        pos_emb_k=query_pos_emb,
        pos_emb_v=None,
        qkv_features=qkv_dim,
        broadcast_dropout=False,
        dropout_rate=attention_dropout_rate,
        kernel_init=initializers.xavier_uniform(),
        bias_init=initializers.zeros,
        bias=True,
        deterministic=deterministic,
        dtype=dtype)

    cross_attn = MultiHeadDotProductAttention.partial(
        num_heads=num_heads,
        pos_emb_q=query_pos_emb,
        pos_emb_k=pos_embedding,
        pos_emb_v=None,
        qkv_features=qkv_dim,
        broadcast_dropout=False,
        key_padding_mask=key_padding_mask,
        dropout_rate=attention_dropout_rate,
        kernel_init=initializers.xavier_uniform(),
        bias_init=initializers.zeros,
        bias=True,
        deterministic=deterministic,
        dtype=dtype)

    mlp = attention_layers.MlpBlock.partial(
        mlp_dim=mlp_dim,
        activation_fn=nn.gelu,
        dtype=dtype,
        dropout_rate=dropout_rate,
        deterministic=deterministic)

    assert obj_queries.ndim == 3
    if pre_norm:
      # self attention block
      x = nn.LayerNorm(obj_queries, dtype=dtype)
      x = self_attn(inputs_q=x)
      x = nn.dropout(x, rate=dropout_rate, deterministic=deterministic)
      x = x + obj_queries
      # cross attention block
      y = nn.LayerNorm(x, dtype=dtype)
      y = cross_attn(inputs_q=y, inputs_kv=encoder_output)
      y = nn.dropout(y, rate=dropout_rate, deterministic=deterministic)
      y = y + x
      # mlp block
      z = nn.LayerNorm(y, dtype=dtype)
      z = mlp(z)
      out = y + z

    else:
      # self attention block
      x = self_attn(inputs_q=obj_queries)
      x = nn.dropout(x, rate=dropout_rate, deterministic=deterministic)
      x = x + obj_queries
      x = nn.LayerNorm(x, dtype=dtype)
      # cross attention block
      y = cross_attn(inputs_q=x, inputs_kv=encoder_output)
      y = nn.dropout(y, rate=dropout_rate, deterministic=deterministic)
      y = y + x
      y = nn.LayerNorm(y, dtype=dtype)
      # mlp block
      z = mlp(y)
      z = y + z
      out = nn.LayerNorm(z, dtype=dtype)

    return out


class Encoder(nn.Module):
  """DETR Transformer Encoder."""

  def apply(self,
            inputs,
            padding_mask=None,
            num_heads=8,
            num_layers=6,
            qkv_dim=512,
            mlp_dim=2048,
            pos_embedding=None,
            normalize_before=False,
            norm=None,
            dropout_rate=0.1,
            attention_dropout_rate=0.1,
            train=True,
            dtype=jnp.float32):
    """Applies Encoder on the inputs.

    Args:
      inputs: nd-array; Input data.
      padding_mask: bool; Binary mask containing 1 for padding tokens.
      num_heads: int; Number of heads.
      num_layers: int; Number of layers.
      qkv_dim: int; Dimension of the query/key/value.
      mlp_dim: int; Dimension of the mlp on top of attention block.
      pos_embedding: nd-array; Positional Embedding to be added to the inputs.
      normalize_before: bool; If use LayerNorm before attention/mlp blocks.
      norm: Flax Module; normalization layer to be applied on the output.
      dropout_rate: float; Dropout rate.
      attention_dropout_rate: float; Dropout rate for attention weights.
      train: bool; Whether it is training.
      dtype: Data type of the computation (default: float32).

    Returns:
      Output of the transformer encoder.
    """
    assert inputs.ndim == 3  # `[batch, height*width, features]`
    x = inputs

    # input Encoder
    for lyr in range(num_layers):
      x = EncoderBlock(
          x,
          qkv_dim=qkv_dim,
          mlp_dim=mlp_dim,
          num_heads=num_heads,
          pos_embedding=pos_embedding,
          pre_norm=normalize_before,
          padding_mask=padding_mask,
          dropout_rate=dropout_rate,
          attention_dropout_rate=attention_dropout_rate,
          deterministic=not train,
          name=f'encoderblock_{lyr}',
          dtype=dtype)

    if norm is not None:
      x = norm(x)
    return x


class Decoder(nn.Module):
  """DETR Transformer Decoder."""

  def apply(self,
            obj_queries,
            encoder_output,
            key_padding_mask=None,
            num_heads=8,
            num_layers=6,
            qkv_dim=512,
            mlp_dim=2048,
            pos_embedding=None,
            query_pos_emb=None,
            normalize_before=False,
            return_intermediate=False,
            dropout_rate=0.1,
            attention_dropout_rate=0.1,
            norm=None,
            train=True,
            dtype=jnp.float32):
    """Applies Decoder on the inputs.

    Args:
      obj_queries: nd-array; Input data for decoder.
      encoder_output: nd-array; Output of encoder, which are encoded inputs.
      key_padding_mask: bool; Mask padding tokens for keys.
      num_heads: int; Number of heads.
      num_layers: int; Number of layers.
      qkv_dim: int; Dimension of the query/key/value.
      mlp_dim: int; Dimension of the mlp on top of attention block.
      pos_embedding: nd-array; Positional Embedding to be added to the inputs.
      query_pos_emb: nd-array; Positional Embedding to be added to the queries.
      normalize_before: bool; If use LayerNorm before attention/mlp blocks.
      return_intermediate: bool; If return the outputs from intermediate layers.
      dropout_rate: float; Dropout rate.
      attention_dropout_rate: float; Dropout rate for attention weights.
      norm: Flax Module; normalization layer to be applied on the output.
      train: bool; Whether it is training.
      dtype: Data type of the computation (default: float32).

    Returns:
      Output of a transformer decoder.
    """
    assert encoder_output.ndim == 3  # `[batch, len, features]`
    assert obj_queries.ndim == 3  # `[batch, num queries, embedding size]`
    y = obj_queries
    outputs = []
    for lyr in range(num_layers):
      y = DecoderBlock(
          y,
          encoder_output,
          qkv_dim=qkv_dim,
          mlp_dim=mlp_dim,
          num_heads=num_heads,
          pos_embedding=pos_embedding,
          query_pos_emb=query_pos_emb,
          pre_norm=normalize_before,
          key_padding_mask=key_padding_mask,
          dropout_rate=dropout_rate,
          attention_dropout_rate=attention_dropout_rate,
          deterministic=not train,
          dtype=dtype,
          name=f'decoderblock_{lyr}')
      if return_intermediate:
        outputs.append(y if norm is None else norm(y))

    if return_intermediate:
      return jnp.stack(outputs, axis=0)
    else:
      return y if norm is None else norm(y)


class DETRTransformer(nn.Module):
  """DETR Transformer."""

  def apply(self,
            inputs,
            padding_mask=None,
            num_queries=100,
            query_emb_size=None,
            num_heads=8,
            num_encoder_layers=6,
            num_decoder_layers=6,
            qkv_dim=512,
            mlp_dim=2048,
            pos_embedding=None,
            query_pos_emb=None,
            return_intermediate_dec=False,
            normalize_before=False,
            dropout_rate=0.1,
            attention_dropout_rate=0.1,
            train=True,
            dtype=jnp.float32):
    """Applies DETRTransformer on the inputs.

    Args:
      inputs: Input data.
      padding_mask: bool; Binary mask containing 1 for padding tokens.
      num_queries: int; Number of object queries. query_emb_size; int; Size of
        the embedding learned for object queries.
      query_emb_size: int; Size of the embedding learned for object queries.
      num_heads: int; Number of heads.
      num_encoder_layers: int; Number of encoder layers.
      num_decoder_layers: int; Number of decoder layers.
      qkv_dim: int; Dimension of the query/key/value.
      mlp_dim: int; Dimension of the mlp on top of attention block.
      pos_embedding: nd-array; Positional Embedding to be added to the inputs.
      query_pos_emb: nd-array; Positional Embedding to be added to the queries.
      return_intermediate_dec: bool; If return the outputs from intermediate
        layers of the decoder.
      normalize_before: bool; If use LayerNorm before attention/mlp blocks.
      dropout_rate: float; Dropout rate.
      attention_dropout_rate: float; Dropout rate for attention weights.
      train: bool; Whether it is training.
      dtype: Data type of the computation (default: float32).

    Returns:
      Output of the DETR transformer.
    """
    encoder_norm = nn.LayerNorm if normalize_before else None
    encoded = Encoder(
        inputs,
        padding_mask=padding_mask,
        num_heads=num_heads,
        num_layers=num_encoder_layers,
        qkv_dim=qkv_dim,
        mlp_dim=mlp_dim,
        pos_embedding=pos_embedding,
        normalize_before=normalize_before,
        norm=encoder_norm,
        dropout_rate=dropout_rate,
        attention_dropout_rate=attention_dropout_rate,
        train=train,
        dtype=dtype,
        name='encoder')

    query_dim = query_emb_size or inputs.shape[-1]
    obj_query_shape = tuple([inputs.shape[0], num_queries, query_dim])
    # note that we always learn query_pos_embed, so we simply use constant
    # zero vectors for obj_queries and later when applying attention, we have:
    # query = query_pos_embed + obj_queries
    obj_queries = jnp.zeros(obj_query_shape)

    decoder_norm = nn.LayerNorm
    output = Decoder(
        obj_queries,
        encoded,
        key_padding_mask=padding_mask,
        num_heads=num_heads,
        num_layers=num_decoder_layers,
        qkv_dim=qkv_dim,
        mlp_dim=mlp_dim,
        pos_embedding=pos_embedding,
        query_pos_emb=query_pos_emb,
        normalize_before=normalize_before,
        return_intermediate=return_intermediate_dec,
        dropout_rate=dropout_rate,
        attention_dropout_rate=attention_dropout_rate,
        norm=decoder_norm,
        dtype=dtype,
        train=train,
        name='decoder')
    return output


class BBoxCoordPredictor(nn.Module):
  """FFN block for predicting bounding box coordinates."""

  def apply(self,
            inputs,
            mlp_dim,
            num_layers=3,
            kernel_init=initializers.lecun_uniform(),
            bias_init=initializers.zeros,
            dtype=jnp.float32):
    """Applies FFN MLP block to inputs.

    Args:
      inputs: nd-array; Input data.
      mlp_dim: int; Size of hidden dimension of dense layers.
      num_layers: int; Number of layers.
      kernel_init: Kernel initialization.
      bias_init: Bias initialization.
      dtype: Data type, e.g. jnp.float32.

    Returns:
      Output of FFN MLP block.
    """

    x = inputs
    for _ in range(num_layers-1):
      x = nn.Dense(
          x,
          mlp_dim,
          kernel_init=kernel_init,
          bias_init=bias_init,
          dtype=dtype)
      x = nn.relu(x)

    x = nn.Dense(
        x, 4, kernel_init=kernel_init, bias_init=bias_init, dtype=dtype)
    output = nn.sigmoid(x)
    return output


class ObjectClassPredictor(nn.Module):
  """Linear Projection block for predicting classification."""

  def apply(self,
            inputs,
            num_classes,
            kernel_init=initializers.lecun_uniform(),
            bias_init=initializers.zeros,
            dtype=jnp.float32):
    """Applies Linear Projection to inputs.

    Args:
      inputs: Input data.
      num_classes: int; Number of output classes. Note that it is assumed that
        num_classes is already counting the no-object class as class 0.
      kernel_init: Kernel initialization.
      bias_init: Bias initialization.
      dtype: Data type, e.g. jnp.float32.

    Returns:
      Output of Linear Projection block.
    """
    return nn.Dense(
        inputs,
        num_classes,
        kernel_init=kernel_init,
        bias_init=bias_init,
        dtype=dtype)


class DETR(nn.Module):
  """Detection Transformer (DETR) model."""

  def apply(self,
            inputs,
            num_classes,
            padding_mask=None,
            hidden_dim=512,
            num_queries=100,
            query_emb_size=None,
            transformer_num_heads=8,
            transformer_num_encoder_layers=6,
            transformer_num_decoder_layers=6,
            transformer_qkv_dim=512,
            transformer_mlp_dim=2048,
            transformer_max_input_h_w=50,
            transformer_normalize_before=False,
            backbone_num_filters=64,
            backbone_num_layers=50,
            aux_loss=False,
            dropout_rate=0.1,
            train=True,
            update_batch_stats=None,
            dtype=jnp.float32,
            debug=False):
    """Applies DETR model on the input.

    Args:
      inputs: nd-array; Input data.
      num_classes: int; Number of object classes.
      padding_mask: nd-array; Binary matrix with 1 at padded image regions.
      hidden_dim: int; Hidden dimension of the inputs to the model.
      num_queries: int; Number of object queries, ie detection slot. This is the
        maximal number of objects DETR can detect in a single image. For COCO,
        DETR paper recommends 100 queries.
      query_emb_size: int; Size of the embedding learned for object queries.
      transformer_num_heads: int; Number of transformer heads.
      transformer_num_encoder_layers: int; Number of transformer encoder layers.
      transformer_num_decoder_layers: int; Number of transformer decoder layers.
      transformer_qkv_dim: int; Dimension of the transformer query/key/value.
      transformer_mlp_dim: int; Dimension of the mlp on top of attention block.
      transformer_max_input_h_w: int; Maximum acceptable input height and width.
      transformer_normalize_before: bool; If use LayerNorm before attention/mlp
        blocks.
      backbone_num_filters: int; Num filters in the ResNet backbone.
      backbone_num_layers: int; Num layers in the ResNet backbone.
      aux_loss: bool; If train with auxiliary loss.
      dropout_rate: float; Dropout rate.
      train:  bool; Whether it is training.
      update_batch_stats: bool; Whether update the batch statistics for the
        BatchNorms in the backbone. if None, the value of `train` flag will be
        used, i.e. we update the batch stat if we are in the train mode.
      dtype: Data type of the computation (default: float32).
      debug: bool; Whether the debug mode is enabled. debug=True enables model
        specific logging/storing some values using jax.host_callback.

    Returns:
      Output: dit; that has 'pred_logits' and 'pred_boxes', and potentially
      'aux_outputs'.
    """
    # for now, we only support this case
    assert hidden_dim == transformer_qkv_dim

    if update_batch_stats is None:
      update_batch_stats = train

    # backbone
    x = DETRBackbone(
        inputs,
        num_filters=backbone_num_filters,
        num_layers=backbone_num_layers,
        dtype=dtype,
        update_batch_stats=update_batch_stats,
        name='backbone')

    bs, h, w, _ = x.shape

    if padding_mask is None:
      padding_mask_downsampled = jnp.zeros(
          (bs, h, w), dtype=jnp.bool_)
    else:
      padding_mask_downsampled = jax.image.resize(
          padding_mask.astype(jnp.float32),
          shape=[bs, h, w],
          method='nearest').astype(jnp.bool_)
    pos_emb = InputPosEmbeddingSine(
        padding_mask=padding_mask_downsampled,
        hidden_dim=hidden_dim)

    query_pos_emb = QueryPosEmbedding(
        hidden_dim=hidden_dim,
        num_queries=num_queries)

    # project and reshape to 3 dimensions and project
    x = nn.Conv(x, features=hidden_dim, kernel_size=(1, 1), strides=(1, 1))
    x = x.reshape(bs, h * w, hidden_dim)

    return_intermediate = aux_loss
    decoder_output = DETRTransformer(
        x,
        padding_mask=jnp.reshape(padding_mask_downsampled, [bs, h * w, -1]),
        num_queries=num_queries,
        query_emb_size=query_emb_size,
        num_heads=transformer_num_heads,
        num_encoder_layers=transformer_num_encoder_layers,
        num_decoder_layers=transformer_num_decoder_layers,
        qkv_dim=transformer_qkv_dim,
        mlp_dim=transformer_mlp_dim,
        pos_embedding=pos_emb,
        query_pos_emb=query_pos_emb,
        return_intermediate_dec=return_intermediate,
        normalize_before=transformer_normalize_before,
        dropout_rate=dropout_rate,
        attention_dropout_rate=dropout_rate,
        train=train)

    def output_projection(model_output):
      # classification head
      pred_logits = ObjectClassPredictor(model_output, num_classes=num_classes)
      # bounding box detection head
      pred_boxes = BBoxCoordPredictor(model_output, mlp_dim=hidden_dim)
      return pred_logits, pred_boxes

    if not return_intermediate:
      pred_logits, pred_boxes = output_projection(decoder_output)
      return {'pred_logits': pred_logits, 'pred_boxes': pred_boxes}

    pred_logits, pred_boxes = jax.vmap(output_projection)(decoder_output)
    output = {
        'pred_logits': pred_logits[-1],
        'pred_boxes': pred_boxes[-1],
        'aux_outputs': []
    }
    for lgts, bxs in zip(pred_logits[:-1], pred_boxes[:-1]):
      output['aux_outputs'].append({'pred_logits': lgts, 'pred_boxes': bxs})

    return output


class DETRSetDetectionModel(SetDetectionModel):
  """Transformer model for multi-label classification task."""

  def get_global_metrics_fn(self):
    """Returns a callable metric function for global metrics.

    The return function implements metrics that require the prediction for the
    entire test/validation dataset in one place and has the following API:
      ```metrics_fn(all_pred_list, all_targets_list)```
    If return None, no global metrics will be computed.
    """
    # TODO(mjlm): Determine whether we should parameterize threshold.
    # Note: For nonzero thresholds, if all predictions are thresholded out,
    # the evaluator will currently throw an error.
    coco_evaluator = coco_eval.CocoEvaluator(threshold=0.0)
    return functools.partial(
        coco_global_val_metrics_function, coco_evaluator=coco_evaluator)

  def matcher(self, predictions, targets):
    """Implements a matching function.

    matching function matches output detections against ground truth detections
     and returns indices.

    Args:
      predictions: dict; Dictionary of outputs from a model. Must contain
        'pred_boxes' key.
      targets: dict; Dictionary of ground truth targets. Must contain 'boxes'
        key.

    Returns:
      Matched indices which in the form of a list  of tuples (src, dst), where
      `src` and `dst` are indices of corresponding source and target detections.
    """
    if self.hparams.get('matcher') is None:
      return super().matcher(predictions, targets)

    elif self.hparams.get('matcher') == 'hungarian':
      return onp.asarray(
          model_utils.hungarian_matcher(
              predictions,
              targets,
              bbox_loss_coef=self.hparams.get('bbox_loss_coef ', 1.0),
              giou_loss_coef=self.hparams.get('giou_loss_coef ', 1.0),
              class_loss_coef=self.hparams.get('class_loss_coef ', 1.0),
              target_is_onehot=self.dataset_meta_data['target_is_onehot']))

  def build_flax_module(self):
    return DETR.partial(
        num_classes=self.dataset_meta_data['num_classes'],
        hidden_dim=self.hparams.get('hidden_dim', 512),
        num_queries=self.hparams.get('num_queries', 100),
        query_emb_size=self.hparams.get('query_emb_size', None),
        transformer_num_heads=self.hparams.get('transformer_num_heads', 8),
        transformer_num_encoder_layers=self.hparams.get(
            'transformer_num_encoder_layers', 6),
        transformer_num_decoder_layers=self.hparams.get(
            'transformer_num_decoder_layers', 6),
        transformer_qkv_dim=self.hparams.get('transformer_qkv_dim', 512),
        transformer_mlp_dim=self.hparams.get('transformer_mlp_dim', 2048),
        transformer_max_input_h_w=self.hparams.get('transformer_max_input_h_w',
                                                   50),
        transformer_normalize_before=self.hparams.get(
            'transformer_normalize_before', False),
        backbone_num_filters=self.hparams.get('backbone_num_filters', 64),
        backbone_num_layers=self.hparams.get('backbone_num_layers', 50),
        aux_loss=self.hparams.get('aux_loss', False),
        dropout_rate=self.hparams.get('dropout_rate', 0.1),
        dtype=jnp.float32)

  def default_flax_module_hparams(self):
    return ml_collections.ConfigDict(
        dict(
            hidden_dim=32,
            num_queries=8,
            query_emb_size=None,
            transformer_num_heads=2,
            transformer_num_encoder_layers=1,
            transformer_num_decoder_layers=1,
            transformer_qkv_dim=32,
            transformer_mlp_dim=32,
            transformer_max_input_h_w=50,
            transformer_normalize_before=False,
            backbone_num_filters=32,
            backbone_num_layers=1,
            aux_loss=False,
            matcher=None,
            dropout_rate=0.1))
