# Lint as: python3
r"""Main script for the Scenic project."""

import json
import os

from absl import app
from absl import flags
from absl import logging
from flax.metrics import tensorboard
import jax
from jax.config import config
from scenic import configdict
from scenic import train
from scenic.dataset_lib import datasets
from scenic.model_lib import models
import tensorflow.compat.v2 as tf
from tensorflow.io import gfile

FLAGS = flags.FLAGS
flags.DEFINE_string('experiment_dir', None, 'Experiment directory.')
flags.DEFINE_string('config', None, 'Experiment configuration in the form '
                    'of a json string.')



def run(hparams, experiment_dir):
  """Prepares model, and dataset for training.

  This creates summary directories, summary writers, model definition, and
  builds datasets to be sent to the main training script.

  Args:
    hparams:  ConfigDict; Hyper parameters.
    experiment_dir: string; Root directory for the experiment.
  """
  master = jax.host_id() == 0
  # set up the train_dir and log_dir
  gfile.makedirs(experiment_dir)
  experiment_dir = os.path.join(experiment_dir, 'r=3/')
  gfile.makedirs(experiment_dir)

  tb_summary_writer = None
  if master and hparams.write_summary:
    tensorboard_dir = os.path.join(experiment_dir, 'tb_summaries')
    gfile.makedirs(tensorboard_dir)
    tb_summary_writer = tensorboard.SummaryWriter(tensorboard_dir)

  device_count = jax.device_count()
  logging.info('device_count: %d', device_count)
  logging.info('num_hosts : %d', jax.host_count())
  logging.info('host_id : %d', jax.host_id())

  rng = jax.random.PRNGKey(hparams.rng_seed)
  logging.info('rng: %s', rng)

  model_cls = models.get_model(hparams.model_name)
  dataset_builder = datasets.get_dataset(hparams.dataset_name)

  batch_size = hparams.batch_size
  if batch_size % device_count > 0:
    raise ValueError(f'Batch size ({batch_size}) must be divisible by the '
                     f'number of devices ({device_count})')

  if hparams.get('eval_batch_size', None):
    eval_batch_size = hparams.eval_batch_size
    if eval_batch_size % device_count > 0:
      raise ValueError(f'Eval batch size ({eval_batch_size}) must be divisible '
                       f'by the number of devices ({device_count})')

  local_batch_size = batch_size // jax.host_count()
  device_batch_size = batch_size // device_count
  logging.info('local_batch_size : %d', local_batch_size)
  logging.info('device_batch_size : %d', device_batch_size)

  dataset = dataset_builder(
      batch_size=local_batch_size,
      eval_batch_size=local_batch_size,
      num_shards=jax.local_device_count(),
      dtype_str=hparams.data_dtype_str)

  train.main(rng, model_cls, dataset, hparams, experiment_dir,
             tb_summary_writer)


def main(_):
  # enables eager execution: Necessary to use the TFDS loader
  tf.enable_v2_behavior()
  # make sure TF does not allocate gpu memory
  tf.config.experimental.set_visible_devices([], 'GPU')

  # load configs from a config json string
  hparams_json_str = FLAGS.config
  hparams = configdict.ConfigDict(json.loads(hparams_json_str))


  logging.info('Hyperparameters: %s', hparams)

  # set tensorflow random seed
  tf.random.set_seed(jax.host_id() + hparams.rng_seed)

  experiment_dir = FLAGS.experiment_dir
  logging.info('Experiment directory: %s', experiment_dir)
  run(hparams, experiment_dir)


if __name__ == '__main__':
  config.config_with_absl()
  app.run(main)
