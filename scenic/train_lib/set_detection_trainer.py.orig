"""Training script for the set detection task.

Note that currently it assumes that the matching stage should be done on CPU,
given that Hungarian matching can't be done on TPU.
"""

import functools
import time

from flax import jax_utils
from flax import nn
import jax
from jax.experimental.optimizers import clip_grads
import jax.numpy as jnp
import numpy as onp
from scenic.dataset_lib import dataset_utils
from scenic.debug_lib import debug_utils
from scenic.train_lib import lr_schedules
from scenic.train_lib import optimizers
from scenic.train_lib import train_utils


def normalize_metrics_summary(metrics_summary, split,
                              object_detection_loss_keys):
  """Normalizes the metrics in the given metrics summary.

  Note that currently we only support metrics of the form 1/N sum f(x_i).

  Args:
    metrics_summary: dict; Each value is a sum of a calculated metric over all
      examples.
    split: str; Split for which we normalize the metrics. Used for logging.
    object_detection_loss_keys: list; A loss key used for computing the object
      detection loss.

  Returns:
    Normalized metrics summary.

  Raises:
    TrainingDivergedError: Due to observing a NaN in the metrics.
  """
  for key, val in metrics_summary.items():
    metrics_summary[key] = val[0] / val[1]
    if onp.isnan(metrics_summary[key]):
      raise train_utils.TrainingDivergedError(
          'NaN detected in {}'.format(f'{split}_{key}'))

  # compute and add object_detection_loss using globally normalize terms
  object_detection_loss = 0
  for loss_term_key in object_detection_loss_keys:
    object_detection_loss += metrics_summary[loss_term_key]
  metrics_summary['object_detection_loss'] = object_detection_loss

  return metrics_summary


def train_forward_pass(train_state, batch):
  """Runs the forward pass of the model in train mode and get the outputs.

  Note that we don't update the train_state and basically don't change the RNG
  so for the next time we use the train_state to make predictions and compute
  the gradient, we will generate the same output.

  Args:
    train_state: TrainState; The state of training including the current
      global_step, model_state, rng, and optimizer. The buffer of this argument
      can be donated to the computation.
    batch: A single batch of data. The buffer of this argument can be donated to
      the computation.

  Returns:
    Predictions of the model.
  """
  _, rng = jax.random.split(train_state.rng)
  # bind the rng to the host/device we are on.
  model_rng = train_utils.bind_rng_to_host_device(
      rng, axis_name='batch', bind_to=['host', 'device'])

  # forward pass to get predictions (used for matching)
  with nn.stateful(train_state.model_state) as new_model_state:
    with nn.stochastic(model_rng):
      predictions = train_state.optimizer.target(
          batch['inputs'], train=True, debug=False)

  # NOTE: new_model_state should not be used to update the train_state. In fact
  # nothing in train_state should be changed in this pass
  del new_model_state

  return predictions


def eval_forward_pass(train_state, batch):
  """Runs the forward pass of the model in eval mode and get the outputs.

  Args:
    train_state: TrainState; The state of training including the current
      global_step, model_state, rng, and optimizer. The buffer of this argument
      can be donated to the computation.
    batch: A single batch of data. The buffer of this argument can be donated to
      the computation.

  Returns:
    Predictions of the model.
  """
  # forward pass to get predictions (used for matching)
  with nn.stateful(train_state.model_state, mutable=False):
    predictions = train_state.optimizer.target(
        batch['inputs'], train=False, debug=False)
  return predictions


def train_step(train_state,
               batch,
               matches,
               learning_rate_fn,
               loss_and_metrics_fn,
               max_grad_norm=None,
               debug=False):
  """Runs a single step of training.

  Given the state of the training and a batch of data, computes
  the loss and updates the parameters of the model.

  Note that in this code, the buffers of the first (train_state) and second
  (batch) arguments are donated to the computation.

  Args:
    train_state: TrainState; The state of training including the current
      global_step, model_state, rng, and optimizer. The buffer of this argument
      can be donated to the computation.
    batch: A single batch of data. The buffer of this argument can be donated to
      the computation.
    matches: nd-array: alignment of predictions with targets to be used for
      computing the loss.
    learning_rate_fn: learning rate scheduler which give the global_step
      generates the learning rate.
    loss_and_metrics_fn: A function that given model predictions, a batch, and
      parameters of the model calculates the loss as well as metrics.
    max_grad_norm: float; Maximum gradient norm used for gradient clipping. If
      set to None, no gradient clipping happens.
    debug: bool; Whether the debug mode is enabled during training.
      `debug=True` enables model specific logging/storing some values using
      jax.host_callback.

  Returns:
    Updated state of training and calculated metrics and the learning rate.

  """
  new_rng, rng = jax.random.split(train_state.rng)
  # bind the rng to the host/device we are on.
  model_rng = train_utils.bind_rng_to_host_device(
      rng, axis_name='batch', bind_to=['host', 'device'])

  def training_loss_fn(flax_module):
    with nn.stateful(train_state.model_state) as new_model_state:
      with nn.stochastic(model_rng):
        predictions = flax_module(batch['inputs'], train=True, debug=debug)
    loss, metrics = loss_and_metrics_fn(
        predictions, batch, matches=matches, model_params=flax_module.params)
    return loss, (new_model_state, metrics)

  compute_gradient_fn = jax.value_and_grad(training_loss_fn, has_aux=True)
  step = train_state.global_step
  lr = learning_rate_fn(step)
  (train_cost,
   (new_model_state,
    metrics)), grad = compute_gradient_fn(train_state.optimizer.target)

  if max_grad_norm is not None:
    grad = clip_grads(grad, max_grad_norm)

  del train_cost
  # re-use same axis_name as in the call to `pmap(...train_step...)` below
  grad = jax.lax.pmean(grad, axis_name='batch')
  new_optimizer = train_state.optimizer.apply_gradient(grad, learning_rate=lr)
  new_train_state = train_state.replace(
      global_step=step + 1,
      optimizer=new_optimizer,
      model_state=new_model_state,
      rng=new_rng)
  return new_train_state, metrics, lr


def eval_step(train_state, batch, matches, loss_and_metrics_fn, debug=False):
  """Runs a single step of training.

  Note that in this code, the buffer of the second argument (batch) is donated
  to the computation.

  Args:
    train_state: TrainState, the state of training including the current
      global_step, model_state, rng, and optimizer. The buffer of this argument
      can be donated to the computation.
    batch: A single batch of data.
    matches: nd-array: alignment of predictions with targets to be used for
      computing the loss.
    loss_and_metrics_fn: A function that given model predictions, a batch, and
      parameters of the model calculates the loss as well as metrics.
    debug: bool; Whether the debug mode is enabled during evaluation.
      `debug=True` enables model specific logging/storing some values using
      jax.host_callback.

  Returns:
    predictions and calculated metrics.
  """
  flax_module = train_state.optimizer.target
  with nn.stateful(train_state.model_state, mutable=False):
    predictions = flax_module(batch['inputs'], train=False, debug=debug)
  _, metrics = loss_and_metrics_fn(
      predictions, batch, matches=matches, model_params=flax_module.params)

  # collect predictions and batches from all hosts
  predictions = jax.lax.all_gather(predictions, 'batch')
  batch = jax.lax.all_gather(batch, 'batch')
  return batch, predictions, metrics


def get_matching(predictions, batches, matching_fn):
  """Generates matches in for the given preds and targets using the matching_fn.

  This is done on CPU, given the matching functions can't be jitted.

  Args:
    predictions: dict; Predictions of the model: pred_logits and pred_boxes.
    batches: dict; Batches of data containing the targets.
    matching_fn: function; A matching function that aligns the predictions of
      the model with targets.

  Returns:
    Matches from the matching function.
  """
  # unshard: reshape from `[ndev, bs, ...]` to  `[host_bs, ...]`
  predictions = dataset_utils.unshard(predictions)
  targets = dataset_utils.unshard(batches['label'])
  # do the matching
  matches = matching_fn(predictions, targets)
  if 'aux_outputs' in predictions:
    matches = [matches]
    for aux_pred in predictions['aux_outputs']:
      matches.append(matching_fn(aux_pred, targets))
  # return the sharded matches
  return dataset_utils.shard(matches)


def train(rng, model_cls, dataset, hparams, experiment_dir, summary_writer):
  """Main training loop lives in this function.

  Given the model class and dataset, it prepares the items needed to run the
  training, including the TrainState.

  Args:
    rng: Jax rng key.
    model_cls: Model class; A model has a flax_module, a loss_and_metrics_fn,
      and a associated with it.
    dataset: The dataset that has train_iter, eval_iter, meta_data, and
      optionally, test_iter.
    hparams: hyper-parameters for the experiment.
    experiment_dir: Directory in which we do checkpointing and write summary.
    summary_writer: Summary writer object.

  Returns:
    train_sate that has the state of training (including current
      global_step, model_state, rng, and the optimizer), train_summary
      and eval_summary which are dict of metrics. These outputs are used for
      regression testing.
  """
  master = jax.host_id() == 0
  # build the loss_and_metrics_fn, metrics, and flax_module
  model = model_cls(hparams, dataset.meta_data)
  # create flax module
  rng, model_rng = jax.random.split(rng)
  flax_module, model_state, num_trainable_params = train_utils.create_flax_module(
      model.flax_module_def, dataset.meta_data['input_shape'], hparams,
      model_rng, dataset.meta_data.get('input_dtype', jnp.float32))

  # create optimizer
  # we jit this, such that the arrays that are created are created on the same
  # device as the input is, in this case the CPU. Else they'd be on device[0]
  optimizer = jax.jit(
      optimizers.get_optimizer(hparams).create, backend='cpu')(
          flax_module)
  rng, train_rng = jax.random.split(rng)
  train_state = train_utils.TrainState(
      global_step=0,
      optimizer=optimizer,
      model_state=model_state,
      rng=train_rng)
  start_step = train_state.global_step
  if hparams.checkpoint:
    train_state, start_step = train_utils.restore_checkpoint(
        experiment_dir, train_state)
  # replicate the optimzier, state, and rng
  train_state = jax_utils.replicate(train_state)
  del flax_module  # do not keep a copy of the initial model

  # calculate the total number of training steps
  total_steps, steps_per_epoch = train_utils.get_num_training_steps(
      hparams, dataset.meta_data)
  # get learning rate scheduler
  learning_rate_fn = lr_schedules.get_learning_rate_fn(hparams)

  train_forward_pass_pmapped = jax.pmap(train_forward_pass, axis_name='batch')
  train_step_pmapped = jax.pmap(
      functools.partial(
          train_step,
          learning_rate_fn=learning_rate_fn,
          loss_and_metrics_fn=model.loss_function,
          max_grad_norm=hparams.get('max_grad_norm', None),
          debug=hparams.debug_train),
      axis_name='batch',
      # we can donate both buffers of train_state and train_batch
      donate_argnums=(0, 1),
  )
  eval_forward_pass_pmapped = jax.pmap(eval_forward_pass, axis_name='batch')
  eval_step_pmapped = jax.pmap(
      functools.partial(
          eval_step,
          loss_and_metrics_fn=model.loss_function,
          debug=hparams.debug_eval),
      axis_name='batch',
      # we can donate the eval_batch's buffer
      donate_argnums=(1,),
  )
  log_eval_steps = hparams.get('log_eval_steps') or steps_per_epoch
  if not log_eval_steps:
    raise ValueError("'log_eval_steps' should be specified in the config.")
  log_summary_steps = hparams.get('log_summary_steps', 25)
  checkpoint_steps = hparams.get('checkpoint_steps') or log_eval_steps
  # ceil rounding such that we include the last incomplete batch
  total_eval_steps = int(
      onp.ceil(dataset.meta_data['num_eval_examples'] / hparams.batch_size))
  steps_per_eval = hparams.get('steps_per_eval') or total_eval_steps

  train_metrics, extra_training_logs = [], []
  tick = time.time()
  train_summary, eval_summary, eval_global_metrics_summary = None, None, None

  global_metrics_fn = model.get_global_metrics_fn()
  prof = None  # keeps track of start/stop of profiler state
  for step in range(start_step + 1, total_steps + 1):
    train_batch = next(dataset.train_iter)
    # get predictions to create the matches
    train_predictions = train_forward_pass_pmapped(train_state, train_batch)
    # do the matching on CPU
    train_matches = get_matching(train_predictions, train_batch, model.matcher)
    # do the train step given the matches
    train_state, t_metrics, lr = train_step_pmapped(
        train_state, train_batch, matches=train_matches)
    train_metrics.append(train_utils.unreplicate_and_get(t_metrics))

    # additional training logs: time, learning rate, num parameters
    tock = time.time()
    train_logs = {
        'example_per_sec':
            onp.asarray(1.0 / (tock - tick) * hparams.batch_size),
        'learning_rate':
            train_utils.unreplicate_and_get(lr),
        'num_trainable_params':
            onp.asarray(num_trainable_params)
    }
    tick = tock
    extra_training_logs.append(train_logs)

    metrics_normalizer_fn = functools.partial(
        normalize_metrics_summary,
        object_detection_loss_keys=model.loss_terms_weights.keys())

    if (step % log_summary_steps == 0) or (step == total_steps):
      ############### LOG TRAIN SUMMARY ###############
      train_summary = train_utils.log_train_summary(
          step=step,
          train_metrics=train_metrics,
          extra_training_logs=extra_training_logs,
          summary_writer=summary_writer,
          metrics_normalizer_fn=metrics_normalizer_fn)
      # reset metric accumulation for next evaluation cycle
      train_metrics, extra_training_logs = [], []
      #################################################

    if (step % log_eval_steps == 0) or (step == total_steps):
      # TODO(dehghani): Move evaluation into separate function to save memory.
      eval_metrics = []
      eval_all_predictions = []
      eval_all_labels = []
      # sync model state across replicas (in case of having model state, e.g.
      # batch statistic when using batch norm)
      train_state = train_utils.sync_model_state_across_replicas(train_state)
      for _ in range(steps_per_eval):
        eval_batch = next(dataset.valid_iter)
        # get predictions to create the matches
        eval_predictions = eval_forward_pass_pmapped(train_state, eval_batch)
        # do the matching on CPU
        eval_matches = get_matching(eval_predictions, eval_batch, model.matcher)
        # do the eval step given the matches
        (eval_batch_all_hosts, eval_predictions_all_hosts,
         e_metrics) = eval_step_pmapped(
             train_state, eval_batch, matches=eval_matches)
        # aux_outputs are not needed anymore.
        eval_predictions_all_hosts.pop('aux_outputs', None)
        # collect local metrics (returned by the loss function)
        eval_metrics.append(train_utils.unreplicate_and_get(e_metrics))
        # evaluate global metrics on one of the hosts (master), but given
        # predictions collected from all hosts
        if master and global_metrics_fn is not None:
          # unreplicate the output of eval_step_pmapped (used `lax.all_gather`)
          eval_batch_all_hosts = jax_utils.unreplicate(eval_batch_all_hosts)
          eval_predictions_all_hosts = jax_utils.unreplicate(
              eval_predictions_all_hosts)
          # collect preds and labels to be sent for computing global metrics
          eval_all_predictions.extend(
              train_utils.process_and_fetch_to_host(
                  eval_predictions_all_hosts,
                  eval_batch_all_hosts['batch_mask']))
          eval_all_labels.extend(
              train_utils.process_and_fetch_to_host(
                  eval_batch_all_hosts['label'],
                  eval_batch_all_hosts['batch_mask']))

      eval_global_metrics_summary = {}
      if master and global_metrics_fn is not None:
        expected_num_eval_examples = (
            hparams.get('steps_per_eval') *
            hparams.batch_size if hparams.get('steps_per_eval') is not None else
            dataset.meta_data['num_eval_examples'])
        assert (len(eval_all_predictions) == len(eval_all_labels) ==
                expected_num_eval_examples)
        eval_global_metrics_summary = global_metrics_fn(eval_all_predictions,
                                                        eval_all_labels)
      ############### LOG EVAL SUMMARY ###############
      eval_summary = train_utils.log_eval_summary(
          step=step,
          eval_metrics=eval_metrics,
          extra_eval_summary=eval_global_metrics_summary,
          summary_writer=summary_writer,
          metrics_normalizer_fn=metrics_normalizer_fn)

    ##################### CHECK POINTING ############################
    if ((step % checkpoint_steps == 0 and step > 0) or
        (step == total_steps)) and hparams.checkpoint:
      # sync model state across replicas
      train_state = train_utils.sync_model_state_across_replicas(train_state)
      if master:
        train_utils.save_checkpoint(experiment_dir, train_state)

  # wait until computations are done before exiting
  jax.random.normal(jax.random.PRNGKey(0), ()).block_until_ready()
  # return the train and eval summary after last step for regresesion testing
  eval_summary.update(eval_global_metrics_summary)
  return train_state, train_summary, eval_summary
